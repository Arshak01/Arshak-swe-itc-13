{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW5_Pandas.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"irJOuVWENWDP","executionInfo":{"status":"ok","timestamp":1644574105212,"user_tz":-240,"elapsed":10,"user":{"displayName":"Armine Hayrapetyan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13536132577500303581"}}},"source":["import numpy as np\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# scikit-learn"],"metadata":{"id":"dfx6D-EXRZ8f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sN16ukC6NWYw"},"source":["Բացի ``numpy``-ից և ``pandas``-ից այլ գրադարանների օգտագործումն **արգելված է**։\n","\n","**Error handling**\n","\n",">1․ Եթե որպես ֆունկցիայի պարամետր ստանում եք numpy զանգված (վեկտոր կամ մատրից), և այն չի համապատասխանում խնդրում նշված չափին (dimensions) կամ չափերի անհամաձայնություններ կան, ապա վերադարցրեք(return) **\"DimensionError\"** տեքստը\n"]},{"cell_type":"markdown","metadata":{"id":"GCEodKTbRd_r"},"source":["# Homework Exercises"]},{"cell_type":"markdown","metadata":{"id":"1WbPDB3mI7MO"},"source":["Problem1. Տրված են՝ \n","\n","data $\\rightarrow$ numpy մատրից $150 \\times 4$ չափի\n","\n","feature_names $\\rightarrow$ string-երի list 4 էլեմենտներով\n","\n","target $\\rightarrow$ numpy վեկտոր $150$ չափի\n","\n","target_names $\\rightarrow$ string-երի list 3 էլեմենտներով\n","\n","փոփոխականները (որոնք ստեղծված են վերևում)։ Պահանջվում է ստեղծել pandas DataFrame որը կունենա 5 սյուն և 150 տող։ Առաջին 4 սյուներում գրված կլինի 'data' փոփոխականի պարունակությունը։ Իսկ հինգերորդ սյան մեջ կլինի 'target'-ը, բայց ամեն թվի փոխարեն գրված 'target_names'-ի համապատասխան ինդեքսով տարրը։ Առաջին 4 սյուների անունները կլինեն  'feature_names'-ի էլեմենտները (տրված հերթականությամբ), իսկ հինգերորդի անունը կլինի \"target name\": \n","\n","Վերջնական DataFrame-ի առաջին 5 տողերը կունենան հետևյալ տեսքը՝\n","```\n","\tsepal length (cm)\tsepal width (cm)\tpetal length (cm)\tpetal width (cm)\ttarget name\n","0\t     5.1             \t3.5\t                1.4\t           0.2\t          setosa\n","1\t     4.9            \t 3.0                \t1.4           \t0.2\t          setosa\n","2\t     4.7             \t3.2                \t1.3           \t0.2\t          setosa\n","3\t     4.6\t             3.1                \t1.5           \t0.2\t          setosa\n","4\t     5.0             \t3.6                \t1.4           \t0.2\t          setosa\n","```\n","\n","**Ստացված DataFrame֊ը օգտագործվելու է հաջորդ խնդիրներում**։\n"]},{"cell_type":"code","metadata":{"id":"cTN0Ve60jEqT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644493037997,"user_tz":-240,"elapsed":856,"user":{"displayName":"Armine Hayrapetyan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13536132577500303581"}},"outputId":"e4b0d48d-004e-45ed-9fd0-1d268ffb0c32"},"source":["# Run this cell\n","# Do not modify this cell\n","from sklearn.datasets import load_iris\n","iris = load_iris()\n","\n","data = iris['data']\n","feature_names = iris['feature_names']\n","target = iris['target']\n","target_names = iris['target_names']\n","\n","print('First 5 rows:', data[:5], sep='\\n', end='\\n\\n')\n","print('Feature names:', feature_names, sep='\\n', end='\\n\\n')\n","print('Target indices:', target, sep='\\n', end='\\n\\n')\n","print('Target names:', target_names, sep='\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First 5 rows:\n","[[5.1 3.5 1.4 0.2]\n"," [4.9 3.  1.4 0.2]\n"," [4.7 3.2 1.3 0.2]\n"," [4.6 3.1 1.5 0.2]\n"," [5.  3.6 1.4 0.2]]\n","\n","Feature names:\n","['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n","\n","Target indices:\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2]\n","\n","Target names:\n","['setosa' 'versicolor' 'virginica']\n"]}]},{"cell_type":"code","metadata":{"id":"RQZQyi8cO2Cc"},"source":["def get_data_frame(data, feature_names, target, target_names):\n","  \n","  tmp = pd.DataFrame(data, columns = feature_names)\n","  \n","  tmp[\"target name\"] = target_names[target]\n","  \n","  return tmp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"12GdukjGO2HJ"},"source":["# Do not modify this cell\n","df = get_data_frame(data, feature_names, target, target_names)\n","\n","assert isinstance(df, pd.DataFrame)\n","assert df.shape == (150, 5)\n","assert np.all(df.loc[[0, 75, 120], 'target name'].values == target_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IqlAUvbTO2Lo"},"source":["Նախորդ խնդրում ստացված ``df`` աղյուսակի մեջ գրված է ծաղիկների թերթիկների (պսակաթերթի և բաժակաթերթի) երկարությունն ու լայնությունը և համապատասխան ծաղիկի համարը։ {'setosa', 'versicolor', 'virginica'} տեսակները կոդավորված են {0,1,2} թվերով։\n","\n","![picture](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRaU43Ra3xTYTpU2XLBw5yl20Qty3OCJzjDBw&usqp=CAU)\n","\n","Problem2. Գտեք յուրաքանչուր ծաղկատեսակի թերթիկի (պսակաթերթ և բաժակաթերթ)\n","\n","1. միջին երկարությունը\n","2. միջին լայնությունը\n","3. նվազագույն երկարությունը\n","4. նվազագույն լայնությունը\n","5. առավելագույն երկարությունը\n","6. առավելագույն լայնությունը\n","\n","Այս ամենը լցրեք pandas DataFrame-ի մեջ որը ունի հետևյալ սյուները` \n","```python\n","[\"mean sepal length (cm)\", \"mean petal length (cm)\", \"mean sepal width (cm)\", \"mean petal width (cm)\", \"min sepal length (cm)\", \"min petal length (cm)\", \"min sepal width (cm)\", \"min petal width (cm)\", \"max sepal length (cm)\", \"max petal length (cm)\", \"max sepal width (cm)\", \"max petal width (cm)\"]\n","```\n","և \"target name\" ինդեքսը։ Խորհուրդ է տրվում օգտագործել ``pd.group_by`` ֆունկցիան։"]},{"cell_type":"code","metadata":{"id":"eVIqC81LO2QW"},"source":["def get_stats(df):\n","  setosa = df[df['target name'] == 'setosa'][feature_names].mean().values\n","  virginica = df[df['target name'] == 'virginica'][feature_names].mean().values\n","  versicolor = df[df['target name'] == 'versicolor'][feature_names].mean().values\n","\n","  setosa_min = df[df['target name'] == 'setosa'][feature_names].min().values\n","  virginica_min = df[df['target name'] == 'virginica'][feature_names].min().values\n","  versicolor_min = df[df['target name'] == 'versicolor'][feature_names].min().values\n","\n","  setosa_max = df[df['target name'] == 'setosa'][feature_names].max().values\n","  virginica_max = df[df['target name'] == 'virginica'][feature_names].max().values\n","  versicolor_max = df[df['target name'] == 'versicolor'][feature_names].max().values\n","\n","  rows1, row2, rows3 = np.hstack([setosa, setosa_min, setosa_max]), np.hstack([virginica, virginica_min, virginica_max]), np.hstack([versicolor, versicolor_min, versicolor_max])\n","\n","  columns = np.array([[a + ' sepal length (cm)', a + ' sepal width (cm)', a + ' petal length (cm)', a + ' petal width (cm)'] for a in ['mean', 'min', 'max']]).flatten()\n","\n","  a = pd.DataFrame(np.vstack([rows1, rows3, row2]), columns = columns)\n","  a.index = np.array(['setosa', 'versicolor', 'virginica'])\n","  a.index.name = 'target name'\n","  return a[[\"mean sepal length (cm)\", \"mean petal length (cm)\", \"mean sepal width (cm)\", \"mean petal width (cm)\", \"min sepal length (cm)\", \"min petal length (cm)\", \"min sepal width (cm)\", \"min petal width (cm)\", \"max sepal length (cm)\", \"max petal length (cm)\", \"max sepal width (cm)\", \"max petal width (cm)\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tnLzQbGrO2U1"},"source":["# Do not modify this cell\n","df_stats = get_stats(df)\n","assert df_stats.shape == (3, 12)\n","assert all(df_stats.index.to_list() == target_names)\n","assert np.allclose(df_stats.loc[:, \"mean sepal length (cm)\"].values,\n","            np.array([5.006, 5.936, 6.588]))\n","assert np.allclose(df_stats.loc[:, \"min petal width (cm)\"].values,\n","            np.array([0.1, 1.0, 1.4]))\n","assert np.allclose(df_stats.loc[:, \"max petal length (cm)\"].values,\n","            np.array([1.9, 5.1, 6.9]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_stats"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":254},"id":"pKGciHe0cGUx","executionInfo":{"status":"ok","timestamp":1644493306712,"user_tz":-240,"elapsed":426,"user":{"displayName":"Armine Hayrapetyan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13536132577500303581"}},"outputId":"57351d74-0c07-4259-9f78-5dc009a32d60"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-993ac042-772a-4fed-a8dd-bf8daeecaea3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mean sepal length (cm)</th>\n","      <th>mean petal length (cm)</th>\n","      <th>mean sepal width (cm)</th>\n","      <th>mean petal width (cm)</th>\n","      <th>min sepal length (cm)</th>\n","      <th>min petal length (cm)</th>\n","      <th>min sepal width (cm)</th>\n","      <th>min petal width (cm)</th>\n","      <th>max sepal length (cm)</th>\n","      <th>max petal length (cm)</th>\n","      <th>max sepal width (cm)</th>\n","      <th>max petal width (cm)</th>\n","    </tr>\n","    <tr>\n","      <th>target name</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>setosa</th>\n","      <td>5.006</td>\n","      <td>1.462</td>\n","      <td>3.428</td>\n","      <td>0.246</td>\n","      <td>4.3</td>\n","      <td>1.0</td>\n","      <td>2.3</td>\n","      <td>0.1</td>\n","      <td>5.8</td>\n","      <td>1.9</td>\n","      <td>4.4</td>\n","      <td>0.6</td>\n","    </tr>\n","    <tr>\n","      <th>versicolor</th>\n","      <td>5.936</td>\n","      <td>4.260</td>\n","      <td>2.770</td>\n","      <td>1.326</td>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>7.0</td>\n","      <td>5.1</td>\n","      <td>3.4</td>\n","      <td>1.8</td>\n","    </tr>\n","    <tr>\n","      <th>virginica</th>\n","      <td>6.588</td>\n","      <td>5.552</td>\n","      <td>2.974</td>\n","      <td>2.026</td>\n","      <td>4.9</td>\n","      <td>4.5</td>\n","      <td>2.2</td>\n","      <td>1.4</td>\n","      <td>7.9</td>\n","      <td>6.9</td>\n","      <td>3.8</td>\n","      <td>2.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-993ac042-772a-4fed-a8dd-bf8daeecaea3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-993ac042-772a-4fed-a8dd-bf8daeecaea3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-993ac042-772a-4fed-a8dd-bf8daeecaea3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["             mean sepal length (cm)  ...  max petal width (cm)\n","target name                          ...                      \n","setosa                        5.006  ...                   0.6\n","versicolor                    5.936  ...                   1.8\n","virginica                     6.588  ...                   2.5\n","\n","[3 rows x 12 columns]"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"cd7-trlHcXxd"},"source":["Problem3. ``df`` աղյուսակից ջնջեք այն տողերը, որոնց 'sepal width'-ը փոքր է իր տեսակի միջինից (օգտվելով նախորդ խնդրի հաշվարկներից ``df_stats``)։ Փոփոխությունը կատարեք ``df``-ի վրա և ֆունկցիայով ոչինչ մի վերադարձրեք։"]},{"cell_type":"code","metadata":{"id":"17ayVp5WcX1g"},"source":["def remove_small_flowers(df, df_stats):\n","  #Your code here\n","  meanS = df_stats[\"mean sepal width (cm)\"][0]\n","  meanVer = df_stats[\"mean sepal width (cm)\"][1]\n","  meanVirg = df_stats[\"mean sepal width (cm)\"][2]\n","\n","  result_set = np.vstack([(df[\"sepal width (cm)\"][:50] < meanS).values, (df[\"sepal width (cm)\"][50:100] < meanVer).values, (df[\"sepal width (cm)\"][100:150] < meanVirg).values]).flatten()\n","  ind = df[result_set].index\n","  df.drop(index=ind, inplace = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cLg_LROYlRNd"},"source":["# Do not modify this cell\n","assert remove_small_flowers(df, df_stats) is None\n","assert df.shape == (80, 5)\n","assert (df[['petal length (cm)']].min() == 1.0)[0]\n","assert (df[['petal length (cm)']].max() == 6.7)[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"og_NOaWMcX9j"},"source":["Ստորև վանդակն աշխատացնելով ներմուծիր Բոստոն $506\\times13$  չափանի տվյալների բազմությունը, որն իր մեջ պարունակում է Բոստոնի 506 թաղամասերի վերաբերյալ տվյալներ՝ 13 բնութագրիչներով։ Այդ բնութագրիչներն են՝\n","\n","(\"ԱՆՈՒՆ բացատրություն\" ֆորմատով)\n","1. CRIM per capita crime rate by town\n","2. ZN proportion of residential land zoned for lots over 25,000 sq.ft.\n","3. INDUS proportion of non-retail business acres per town\n","4. CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n","5. NOX nitric oxides concentration (parts per 10 million)\n","6. RM average number of rooms per dwelling\n","7. AGE proportion of owner-occupied units built prior to 1940\n","8. DIS weighted distances to five Boston employment centres\n","9. RAD index of accessibility to radial highways\n","10. TAX full-value property-tax rate per $10,000\n","11. PTRATIO pupil-teacher ratio by town\n","12. B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n","13. LSTAT % lower status of the population\n","\n","\n","Իսկ *y փոփոխականը* 506 երկարությամբ numpy վեկտոր է, որը իրենից ներկայացնում է համապատասխան թաղամասերի տների մեդիան գինը (չափման միավորը՝ $1000)։\n","\n","Problem4. Ստեղծեք dataframe X, y  փոփոխականների հիման վրա (Problem 1.-ի նման)։ Բնութագրիչ սյուների անունները սահմանեք ըստ վերը նշված ցանկիժ, իսկ վերջին սյան անունը՝  \"MEDV\"։"]},{"cell_type":"code","source":["from sklearn.datasets import load_boston\n","load_boston()"],"metadata":{"id":"dFLn2BHqtnaO","executionInfo":{"status":"ok","timestamp":1644581800044,"user_tz":-240,"elapsed":883,"user":{"displayName":"Armine Hayrapetyan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13536132577500303581"}},"outputId":"adeceffd-1ca8-4054-99f6-099be81a6b65","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n","\n","    The Boston housing prices dataset has an ethical problem. You can refer to\n","    the documentation of this function for further details.\n","\n","    The scikit-learn maintainers therefore strongly discourage the use of this\n","    dataset unless the purpose of the code is to study and educate about\n","    ethical issues in data science and machine learning.\n","\n","    In this special case, you can fetch the dataset from the original\n","    source::\n","\n","        import pandas as pd\n","        import numpy as np\n","\n","\n","        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n","        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n","        target = raw_df.values[1::2, 2]\n","\n","    Alternative datasets include the California housing dataset (i.e.\n","    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n","    dataset. You can load the datasets as follows::\n","\n","        from sklearn.datasets import fetch_california_housing\n","        housing = fetch_california_housing()\n","\n","    for the California housing dataset and::\n","\n","        from sklearn.datasets import fetch_openml\n","        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n","\n","    for the Ames housing dataset.\n","    \n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["{'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n"," 'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n","         4.9800e+00],\n","        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n","         9.1400e+00],\n","        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n","         4.0300e+00],\n","        ...,\n","        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n","         5.6400e+00],\n","        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n","         6.4800e+00],\n","        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n","         7.8800e+00]]),\n"," 'data_module': 'sklearn.datasets.data',\n"," 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n","        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n"," 'filename': 'boston_house_prices.csv',\n"," 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n","        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n","        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n","        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n","        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n","        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n","        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n","        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n","        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n","        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n","        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n","        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n","        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n","        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n","        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n","        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n","        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n","        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n","        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n","        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n","        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n","        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n","        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n","        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n","        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n","        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n","        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n","        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n","        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n","        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n","        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n","        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n","        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n","        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n","        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n","         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n","        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n","        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n","         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n","         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n","        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n","        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n","        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n","        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n","        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n","        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])}"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"KB01YhiPcYBl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644574117224,"user_tz":-240,"elapsed":1221,"user":{"displayName":"Armine Hayrapetyan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13536132577500303581"}},"outputId":"9438b3b6-c709-4e76-8448-532a8e6b506f"},"source":["# Do not modify this cell\n","from sklearn.datasets import load_boston\n","X, y = load_boston(return_X_y=True)\n","print(X.shape)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["(506, 13)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n","\n","    The Boston housing prices dataset has an ethical problem. You can refer to\n","    the documentation of this function for further details.\n","\n","    The scikit-learn maintainers therefore strongly discourage the use of this\n","    dataset unless the purpose of the code is to study and educate about\n","    ethical issues in data science and machine learning.\n","\n","    In this special case, you can fetch the dataset from the original\n","    source::\n","\n","        import pandas as pd\n","        import numpy as np\n","\n","\n","        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n","        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n","        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n","        target = raw_df.values[1::2, 2]\n","\n","    Alternative datasets include the California housing dataset (i.e.\n","    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n","    dataset. You can load the datasets as follows::\n","\n","        from sklearn.datasets import fetch_california_housing\n","        housing = fetch_california_housing()\n","\n","    for the California housing dataset and::\n","\n","        from sklearn.datasets import fetch_openml\n","        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n","\n","    for the Ames housing dataset.\n","    \n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","source":["X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mt6wKOTpd5lU","executionInfo":{"status":"ok","timestamp":1644493779264,"user_tz":-240,"elapsed":413,"user":{"displayName":"Armine Hayrapetyan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13536132577500303581"}},"outputId":"aaca1b94-a4a7-4c89-9c80-a53d5fcb98bc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n","        4.9800e+00],\n","       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n","        9.1400e+00],\n","       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n","        4.0300e+00],\n","       ...,\n","       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n","        5.6400e+00],\n","       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n","        6.4800e+00],\n","       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n","        7.8800e+00]])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BnjjmhKid8xx","executionInfo":{"status":"ok","timestamp":1644493790099,"user_tz":-240,"elapsed":404,"user":{"displayName":"Armine Hayrapetyan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13536132577500303581"}},"outputId":"a9377648-f4f4-4c29-e933-f34e9c5a397c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n","       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n","       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n","       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n","       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n","       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n","       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n","       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n","       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n","       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n","       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n","       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n","       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n","       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n","       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n","       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n","       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n","       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n","       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n","       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n","       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n","       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n","       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n","       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n","       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n","       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n","       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n","       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n","       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n","       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n","       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n","       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n","       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n","       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n","       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n","        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n","       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n","       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n","        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n","        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n","       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n","       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n","       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n","       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n","       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n","       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"xLHAeDFlcYJP","executionInfo":{"status":"ok","timestamp":1644574154503,"user_tz":-240,"elapsed":276,"user":{"displayName":"Armine Hayrapetyan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13536132577500303581"}}},"source":["def get_data_frame(X, y):\n","  #Your code here\n","  columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n","  df = pd.DataFrame(X, columns=columns)\n","  df['MEDV'] = y\n","  return df\n","  #Your code here"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"5XaR_teLcYNd","executionInfo":{"status":"ok","timestamp":1644574155751,"user_tz":-240,"elapsed":2,"user":{"displayName":"Armine Hayrapetyan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13536132577500303581"}}},"source":["# Do not modify this cell\n","df = get_data_frame(X,y)\n","\n","assert isinstance(df, pd.DataFrame)\n","assert df.shape == (506, 14)\n","assert df.columns.tolist()[:3] == ['CRIM','ZN','INDUS']\n","assert df.columns[-1] == 'MEDV'"],"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# df[df['CHAS'].isna()]\n","pd.set_option('display.max_rows', None)\n","df[df['CHAS'] == 1].sort_values(by='MEDV', ascending=False)[:6]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"6Mueuf0JQks7","executionInfo":{"status":"ok","timestamp":1644574399031,"user_tz":-240,"elapsed":292,"user":{"displayName":"Armine Hayrapetyan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13536132577500303581"}},"outputId":"893cafe0-2c6d-4b5e-cc02-6eabfe6318ff"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-97214dce-55c7-4834-8b90-13985e591c49\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CRIM</th>\n","      <th>ZN</th>\n","      <th>INDUS</th>\n","      <th>CHAS</th>\n","      <th>NOX</th>\n","      <th>RM</th>\n","      <th>AGE</th>\n","      <th>DIS</th>\n","      <th>RAD</th>\n","      <th>TAX</th>\n","      <th>PTRATIO</th>\n","      <th>B</th>\n","      <th>LSTAT</th>\n","      <th>MEDV</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>372</th>\n","      <td>8.26725</td>\n","      <td>0.0</td>\n","      <td>18.10</td>\n","      <td>1.0</td>\n","      <td>0.668</td>\n","      <td>5.875</td>\n","      <td>89.6</td>\n","      <td>1.1296</td>\n","      <td>24.0</td>\n","      <td>666.0</td>\n","      <td>20.2</td>\n","      <td>347.88</td>\n","      <td>8.88</td>\n","      <td>50.0</td>\n","    </tr>\n","    <tr>\n","      <th>370</th>\n","      <td>6.53876</td>\n","      <td>0.0</td>\n","      <td>18.10</td>\n","      <td>1.0</td>\n","      <td>0.631</td>\n","      <td>7.016</td>\n","      <td>97.5</td>\n","      <td>1.2024</td>\n","      <td>24.0</td>\n","      <td>666.0</td>\n","      <td>20.2</td>\n","      <td>392.05</td>\n","      <td>2.96</td>\n","      <td>50.0</td>\n","    </tr>\n","    <tr>\n","      <th>369</th>\n","      <td>5.66998</td>\n","      <td>0.0</td>\n","      <td>18.10</td>\n","      <td>1.0</td>\n","      <td>0.631</td>\n","      <td>6.683</td>\n","      <td>96.8</td>\n","      <td>1.3567</td>\n","      <td>24.0</td>\n","      <td>666.0</td>\n","      <td>20.2</td>\n","      <td>375.33</td>\n","      <td>3.73</td>\n","      <td>50.0</td>\n","    </tr>\n","    <tr>\n","      <th>283</th>\n","      <td>0.01501</td>\n","      <td>90.0</td>\n","      <td>1.21</td>\n","      <td>1.0</td>\n","      <td>0.401</td>\n","      <td>7.923</td>\n","      <td>24.8</td>\n","      <td>5.8850</td>\n","      <td>1.0</td>\n","      <td>198.0</td>\n","      <td>13.6</td>\n","      <td>395.52</td>\n","      <td>3.16</td>\n","      <td>50.0</td>\n","    </tr>\n","    <tr>\n","      <th>162</th>\n","      <td>1.83377</td>\n","      <td>0.0</td>\n","      <td>19.58</td>\n","      <td>1.0</td>\n","      <td>0.605</td>\n","      <td>7.802</td>\n","      <td>98.2</td>\n","      <td>2.0407</td>\n","      <td>5.0</td>\n","      <td>403.0</td>\n","      <td>14.7</td>\n","      <td>389.61</td>\n","      <td>1.92</td>\n","      <td>50.0</td>\n","    </tr>\n","    <tr>\n","      <th>163</th>\n","      <td>1.51902</td>\n","      <td>0.0</td>\n","      <td>19.58</td>\n","      <td>1.0</td>\n","      <td>0.605</td>\n","      <td>8.375</td>\n","      <td>93.9</td>\n","      <td>2.1620</td>\n","      <td>5.0</td>\n","      <td>403.0</td>\n","      <td>14.7</td>\n","      <td>388.45</td>\n","      <td>3.32</td>\n","      <td>50.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97214dce-55c7-4834-8b90-13985e591c49')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-97214dce-55c7-4834-8b90-13985e591c49 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-97214dce-55c7-4834-8b90-13985e591c49');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  MEDV\n","372  8.26725   0.0  18.10   1.0  0.668  ...  666.0     20.2  347.88   8.88  50.0\n","370  6.53876   0.0  18.10   1.0  0.631  ...  666.0     20.2  392.05   2.96  50.0\n","369  5.66998   0.0  18.10   1.0  0.631  ...  666.0     20.2  375.33   3.73  50.0\n","283  0.01501  90.0   1.21   1.0  0.401  ...  198.0     13.6  395.52   3.16  50.0\n","162  1.83377   0.0  19.58   1.0  0.605  ...  403.0     14.7  389.61   1.92  50.0\n","163  1.51902   0.0  19.58   1.0  0.605  ...  403.0     14.7  388.45   3.32  50.0\n","\n","[6 rows x 14 columns]"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"lLXQ1Ai4cYSL"},"source":["Problem5. Վերադարձնել 3 \"ամենաէժան թաղամասերի\" տողերը, որտեղ CRIM-ը մեծ է 0.5֊ից։"]},{"cell_type":"code","metadata":{"id":"PAIxZEaapnQe"},"source":["def three_less_expensive(df):\n","  # Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KY6omfGLpnUY"},"source":["# Do not modify this cell\n","top3 = three_less_expensive(df)\n","assert top3.MEDV.mean() == 5.2  \n","assert top3.INDUS.mean() == 18.1 \n","assert top3.TAX.mean() == 666.0 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hKO58_mpt83g"},"source":["Problem6. Վերադարձնել 6 \"ամենաթանկ թաղամասերի\" տողերը, որոնք գտնվում են Չարլզ գետի ափին։"]},{"cell_type":"code","metadata":{"id":"KmEHbCvEpnYV"},"source":["def three_most_expensive(df):\n","  # Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5kiL2V7upndY"},"source":["# Do not modify this cell\n","top6 = three_most_expensive(df)\n","assert top6.MEDV.mean() == 50.0\n","assert top6.TAX.min() == 198.0\n","assert top6.ZN.max() == 90.0\n","assert isinstance(top6, pd.DataFrame)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZDxLPESGpng3"},"source":["Problem7. Վերադարձնել միջինում 10 ամենաշատ  սենյակներն ունեցող թաղամասերի միջին սենյակների քանակները (``RM``) և տների մեդիան գները։ Արդյունքը պետք է լինի $10 \\times 2$ չափանի DataFrame՝ դասավորված ըստ ``RM`` սյան նվազման կարգով։"]},{"cell_type":"code","metadata":{"id":"HHSrktITpnk2"},"source":["def ten_most_rooms(df):\n","  # Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qNPI7gvkx6Gs"},"source":["# Do not modify this cell\n","top10 = ten_most_rooms(df)\n","assert top10.iloc[0].values.tolist() ==  [8.78, 21.9]\n","assert top10.mean().values.tolist() == [8.4388, 44.83]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1EOVdGvLywaB"},"source":["Problem8. ``df``-ում ավելացնել նոր տող ըստ տրված 14 երկարությամբ ``x`` վեկտորի։"]},{"cell_type":"code","metadata":{"id":"lQUlvxb5yzre"},"source":["def add_row(df, x):\n","  # Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rjTCu5OdzGjV"},"source":["# Do not modify this cell\n","assert len(df) == 506\n","x = np.array([0.006, 18, 2.31, 0, 0.5, 6.5, 65, 4, 1, 296, 15, 396, 5, 19])\n","assert add_row(df, x) is None\n","assert len(df) == 507\n","assert (df.iloc[-1].values == x).all()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-gtE930n1_i_"},"source":["Problem9. ``df``-ից ջնջել առաջին սյունը։"]},{"cell_type":"code","metadata":{"id":"uC4o3Yzy1_uG"},"source":["def remove_first_col(df):\n","  # Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xRgAvIjW1_yg"},"source":["# Do not modify this cell\n","assert df.shape[1] == 14\n","assert remove_first_col(df) is None\n","assert df.shape[1] == 13\n","assert df.columns[0] == 'ZN'\n","assert 'CRIM' not in df.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zNp_bIS21_2Y"},"source":["Problem10. Օգտագործելով ``groupby`` ֆունկցիան գտնել գետի մոտ գտնվող և չգտնվող թաղամասերի բնութագրիչների միջինները։"]},{"cell_type":"code","metadata":{"id":"tjGRcoxQ1_7A"},"source":["def group_by_river(df):\n","  # Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L6zJXoAi1_-q"},"source":["# Do not modify this cell\n","river_df = group_by_river(df)\n","assert river_df.shape == (2, 12)\n","assert river_df.index.name == 'CHAS'\n","assert river_df.MEDV.values.tolist() == [22.08728813559324, 28.44]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ov0-Jqpg2ACz"},"source":["Problem11. ``'Military Expenditure.csv'`` ֆայլի տվյալները կարդացեք DataFrame-ով և վերադարձրեք առաջին 10 տողերը, ինչպես նաև ամբողջ DataFrame-ը։"]},{"cell_type":"code","metadata":{"id":"WjMicO7f2AGu"},"source":["def read_return_top10(file_name):\n","  # your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhdD_dwd2AKt"},"source":["# Do not modify this cell\n","top10, df = read_return_top10('Military Expenditure.csv')\n","assert top10.iloc[8]['Name'] == 'Armenia'\n","assert top10.shape == (10, 63)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1umQDIiu8R4E"},"source":["Military Expenditure dataset-ը պատրաստվել է Ստոկհոլմի խաղաղության միջազգային հետազոտությունների ինստիտուտի (SIPRI) կողմից և պարունակում է ավելի քան 200 պետությունների 1960-2018 թվականներին կատարած ռազմական ծախսերը դոլարներով։\n","\n","Problem12. Ջնջել այն տողերը որոնց 'Type' սյունը \"Country\" *չէ*։"]},{"cell_type":"code","metadata":{"id":"77I9fD9s8R7t"},"source":["def remove_non_countries(df):\n","  # Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RrKAWAfH8R_T"},"source":["# Do not modify this cell\n","assert remove_non_countries(df) is None\n","assert df.Type.nunique() == 1\n","assert df.shape == (202, 63)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GkG4ZCdV8SDV"},"source":["Problem13. Ջնջել 'Code', 'Type', 'Indicator Name' սյուները։"]},{"cell_type":"code","metadata":{"id":"ZMa3faHG8SHR"},"source":["def remove_some_cols(df):\n","  # Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f1I_nh2C-huU"},"source":["# Do not modify this cell\n","assert remove_some_cols(df) is None\n","assert df.shape == (202, 60)\n","assert df.columns[1] == '1960'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CwC6aiht-4yh"},"source":["Problem14. Ստացված dataframe-ը գրել(պահպանել) 'MilitaryExpenditureSmall.csv' ֆայլի վրա **այնպես, ինչպես որ կա**։"]},{"cell_type":"code","metadata":{"id":"WNOW65Gi-428"},"source":["def save_df(df, file_name):\n","  # your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bCfx11nU-47K"},"source":["# Do not modify this cell\n","file_name = 'MilitaryExpenditureSmall.csv'\n","save_df(df, file_name)\n","small_df = pd.read_csv(file_name)\n","assert small_df.iloc[0, 0] == 'Aruba'\n","assert small_df.shape[1] == 60"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S_YLkrnz-4_d"},"source":["Problem15. Վերադարձնել Հայաստանին համապատասխանող տողի այն տվյալները/վանդակները որոնք դատարկ չեն։"]},{"cell_type":"code","metadata":{"id":"3DfUpEo6AvHl"},"source":["def info_arm(df):\n","  # your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4oqBF6fnAvLZ"},"source":["# Do not modify this cell\n","arm = info_arm(df)\n","assert arm.shape == (1, 26)\n","assert arm.iloc[:, 1:].max(axis=1).values[0] == 608854649.9\n","assert '1994' not in arm.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LaQ2lGT0AvPv"},"source":["Problem16. Վերադարձնել DataFrame, որտեղ կլինի պետության անունը՝ որպես ինդեքս և յուրաքանչյուր պետության միջին տարեկան ծախսը՝ որպես ``'mean_expense'`` սյուն՝ գրված նվազման կարգով։  Վերջնական աղյուսակում չպետք է լինեն այնպիսի երկրներ, որոնց ծախսերի տվյալները ընդհանրապես առկա չեն կամ 0 են։"]},{"cell_type":"code","metadata":{"id":"nGPb80DRAvSs"},"source":["def per_country_mean_expense(df):\n","  # your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGsnpiYSHTCx"},"source":["# Do not modify this cell\n","grouped_df = per_country_mean_expense(df)\n","assert grouped_df.loc['Armenia'][0] == arm.iloc[:,1:].mean(axis=1).values[0]\n","assert grouped_df.shape == (164, 1)\n","assert grouped_df.index[0] == 'United States'\n","assert grouped_df.index[-1] == 'Haiti'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YylBqLaCJ-21"},"source":["Problem17. Տրված է ՝ $10 \\times 4$ չափնի ```pandas.DataFrame (df)```։ Հարկավոր է գրել ֆունկցիա, որը կստեղծի նոր ```pandas.DataFrame```, որի մեջ կլինեն ```df```-ի տողերն ու սյուները և 2 նոր սյուն ```nearest_row```  և ```dist``` որոնց մեջ գրված կլինեն ամենամոտիկ տողի ```index```-ը և էվկլիդյան հեռավորությունը այդ տողերի միջև։ \n"]},{"cell_type":"code","metadata":{"id":"gEl1EDxNP8Ll"},"source":["def add_columns(df):\n","  # Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmLJwz_X8SLy"},"source":["# Do not modify this cell\n","np.random.seed(42)\n","df = pd.DataFrame(np.random.randint(1, 100, 40).reshape(10, -1),\n","                  columns=list('pqrs'),\n","                  index=list('abcdefghij'))\n","new_df = add_columns(df)\n","assert isinstance(new_df, pd.DataFrame) \n","assert new_df.loc['a']['nearest_row'] == 'g' \n","assert new_df.nearest_row.value_counts()[0] == 4\n","assert id(new_df) != id(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n3ZSEEqAQush"},"source":["Problem18. Տրված է՝ $93 \\times 27 $ չափանի ```pandas.DataFrame (df)```։ Հարկավոր է գրել ֆունկցիա, որը կստեղծի նոր ```pandas.DataFrame```, որի մեջ կլինեն ```df```-ի տողերն ու սյուները, բացառությամբ ```Type``` սյան, որի փոխարեն կլինեն մի քանի սյուներ՝ ստացված HW4-ի 4-րդ խնդրի ֆունկցիայի միջոցով։ Սյուների անունները կլինեն ```Type``` սյան արժեքները (Midsize, Small, ...):\n"]},{"cell_type":"code","metadata":{"id":"D09oh5NBQ95V"},"source":["def convert(df):\n","  # Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-54pHeXQ99q"},"source":["# Do not modify this cell\n","df = pd.read_csv(\n","    'https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n","new_df = convert(df)\n","assert convert(df).iloc[0]['Small'] == 1 \n","assert isinstance(new_df, pd.DataFrame)\n","assert id(new_df) != id(df)\n","assert new_df.shape == (93, 32)\n","assert new_df.columns[-5:].tolist() == ['Large', 'Midsize',\n","                                        'Small', 'Sporty', 'Van']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eUNZhXmLQ-DY"},"source":["Problem19. Նախորդ խնդրում ստացված dataset-ի  ```Min.price``` և ```Max.price``` սյուների բացակայող արժեքները լրացնել համապատասխանաբար այդ սյուների  միջինով և մեդիանով՝ օգտագործելով ``apply()`` մեթոդը:\n"]},{"cell_type":"code","metadata":{"id":"MZbU-659ScnJ"},"source":["def fill_NaN(df):\n","  # Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MdWZqsmmTKAc"},"source":["# Do not modify this cell\n","assert isinstance(new_df, pd.DataFrame)\n","other_df = fill_NaN(new_df)\n","assert abs(other_df.iloc[3]['Min.Price'] - 17.118605) < 0.0001\n","assert abs(other_df.iloc[4]['Max.Price'] - 19.15) < 0.0001"],"execution_count":null,"outputs":[]}]}